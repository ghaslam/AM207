{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##AM207 Project Proposal Predicting Water Well Failure\n",
    "###Team Members: Sam Kim, Harvard College '15, and Gareth Haslam, Ext. School\n",
    "###Date: 10th April 2015\n",
    "\n",
    "Predicting failure of water wells is an important issues for millions of people in developing countries who rely on these wells for their clean drinking water. Using the dataset available as part of the DrivenData.org challenge we aim to use Bayesian Methods to investigate how to better predict failure..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "####Introduction\n",
    "\n",
    "We have decided to tackle the challenge presented by DRIVENDATA at http://www.drivendata.org/competitions/7/page/23/. The data is given by Taarifa, which is an open source platform for reporting infrastructure issues, and the Tanzanian Ministry of Water. The goal is to \"predict the operating condition of a waterpoint for each record in the dataset.\" The possible classifications are \"functional,\"  \"non functional,\" and \"functional needs repair.\" Being able to predict which waterpoints will fail will improve maintenance operations and infrastructure upkeep to ensure that communities across Tanzania have access to clean water without spending resources constantly monitoring each waterpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####Data\n",
    "\n",
    "The data has been provided by the challenge, and includes 39 different variables on what kind of pump is operating, its location, when it was installed, and how it is managed. There are 59400 data points available for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####Methodology\n",
    "\n",
    "We plan on using Bayesian modeling to predict the functional status of each waterpoint as a function of all the variables.\n",
    "\n",
    "Naive Bayes gives us:\n",
    "\n",
    "$$P(status|\\Theta)\\propto P(\\Theta|status)P(status)$$\n",
    "\n",
    "where $\\Theta$ describes the parameters of our model. In the simplest case, it can simply be a product of the conditional probability for each attribute, $P(\\theta_i|status)$. If we want to build a more complex model, we would include parameters $\\alpha_i$ to relate the attributes to each other and to the status, such as $P(broken|age)=\\alpha_1+\\alpha_2\\cdot age$. Because we have very little experience in this field and know little about the model, the parameters $\\alpha_i$ would also have distributions with hyperparameters, $\\beta_i$. This chain can extend as far as we want.\n",
    "\n",
    "In the end, we are sampling from the joint posterior distribution for all the parameters, $\\theta_i, \\alpha_i, \\beta_i, ...$, which is $P(\\Theta, \\alpha, \\beta,... | status)$ to build the model, and then using this distribution to predict the status for unknown data.\n",
    "\n",
    "Sampling the joint posterior distribution can be done through any of the methods taught in class, including Metropolis-Hastings and its numberous variants, Gibbs, slice sampling, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
