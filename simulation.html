<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
            <meta http-equiv="X-UA-Compatible" content="IE=edge">
                <meta name="viewport" content="width=device-width, initial-scale=1.0">
                    <meta name="description" content="">
                        <meta name="author" content="">
                            <link rel="shortcut icon" href="img/favicon.ico">
                                
                                <title>AM 207 Final Project</title>
                                
                                <!-- Bootstrap core CSS -->
                                <link href="//netdna.bootstrapcdn.com/bootswatch/3.1.1/yeti/bootstrap.min.css" rel="stylesheet">
                                    
                                    <!-- Custom styles for this template -->
                                    <link href="http://getbootstrap.com/examples/jumbotron-narrow/jumbotron-narrow.css" rel="stylesheet">
                                        
                                        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
                                        <!--[if lt IE 9]>
                                         <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
                                         <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
                                         <![endif]-->
                                        
                                        <script type="text/x-mathjax-config">
                                            MathJax.Hub.Config({
                                                               tex2jax: {inlineMath: [['$','$']]}
                                                               });
                                            </script>
                                        <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
                                            </script>
                                        </head>
    
    <body>
        
        <div class="container">
            <div class="header">
                <ul class="nav nav-pills pull-right">
                    <li class="active"><a href="index.html">Home</a></li>
                    <li><a href="simulation.html">PREDICTION</a></li>
                    <li><a href="optimization.html">BEST ROUTE</a></li>
                    <li><a href="https://github.com/ghaslam/AM207/" target="_blank">
                        <img src="img/GitHub-Mark-32px.png" height="18" style="vertical-align:text-top;"/> Code</a></li>
                </ul>
                <h3 class="text-muted">AM 207 Final Project</h3>
            </div>
            
            <div class="container">
                <h2>Predicting water pump failure in Tanzania and optimising maintenance routes</h2>
                <h3 class="text-muted">Predicting functional status of water pumps using Bayesian Methods</h3>
            </div>
            
            <div class="row marketing">
                <div class="col-md-12">
                    
                    <h4>Model Classification</h4>
                    
                    <p>Bayesian methods are only compatible with numerical data and do not work directly with classification problems, so we need to convert the categorical data and classes into numerical data and labels.</p>
                    
                    $$\begin{aligned}
                    \mathrm{functional: } & 0.67\leq y_i  &&  \\
                    \mathrm{needs-repair: } & 0.33<y_i<0.67 && \\
                    \mathrm{non-functional: }& y_i \leq 0.33 && \end{aligned}$$
                    
                    <p>The assumption that the 3 labels lie on a linear spectrum is not necessarily a safe assumption, and the limits are set rather arbitrarily. A more natural and common method in machine learning is to build a classifier that decides between 2 classes. In this case, we can either build 3 one-versus-one classifiers or 3 one-versus-rest classifiers and use majority vote (or probabilities in the case of a tie) to make the final classification.</p>
                    
                    <h5>Categorical data</h5>
                    
                    <p> Many of the data features are categorical data that do not have any numerical interpretation, so we cannot convert them the same way that we converted our label. For example, the "installer" feature has labels such as "UNICEF," "Roman," and "Artisan." To deal with these, we use one-of-k representation in which we add a new feature column for every unique value. For example, we would add the columns "installer=UNICEF," "installer=Roman," and "installer=Artisan." The "installer=UNICEF" would be 1 if that data's "installer" was "UNICEF," and 0 otherwise. So if there are $k$ unique values for a particular categorical feature, then for each data point, we add on a vector of length $k$ which has a single 1 and $k-1$ 0s.</p>
                    
                    <h4>The model</h4>
                    
                    <p>We model $y_i$ using a logistic function that constrains the range to $0 < y_i < 1$, and the parameter for the logistic function is controlled by the features and weights, which are also parameters that we need to calculate. Our model comes from the assumption that there are certain factors impacting decay rate, and so the functionality is dependent on this decay rate. We then select features from the data which we have a prior belief to have a strong influence on functionality, choose priors on their distributions and construct a Metropolis-Hastings Sampler to select the optimum value for each parameter. New predictions of functionality can then be made from this model. We also add on a term for noise, $\epsilon_i$, which we assume is Gaussian noise controlled by the standard deviation $\sigma$. </p>
                    
                    $$\begin{aligned}
                    y_i &= \frac{1}{1+e^{\alpha_i}}+\sigma\epsilon_i \\
                    \alpha_i &= \beta_0 + \beta_1 x_{i,1} + \beta_2 x_{i,2} + ... + \beta_n x_{i,n}\end{aligned}$$
                    
                    <p>There are $n$ features and $n+2$ parameters ($n+1$ $\beta$s and $\sigma$). The parameters are found by sampling from the posterior: </p>
                    $$\begin{aligned}
                    p(Y,\Theta)=p(Y|\Theta)p(\Theta)\end{aligned}$$
                    
                    <h4>Prediction results</h4>

                    <p>Figure <a href="#3">3</a> shows shows the trace plot of the model parameters with blockwise updating and componentwise updating. These are after the burn-in period. Blockwise updating has an acceptance rate of nearly 0 because we are updating 8 parameters at a time. Componentwise updating has a much higher acceptance rate, although at a huge time cost. Figure <a href="#4">4</a> shows the distribution of the samples as a two-dimensional histogram.</p>
                    
                    <div class="panel panel-info">
                    <a name="2"></a>
                    <div class="panel-heading">Figure 2</div>
                    <div class="panel-body">
                    <img src="img/trace_block.png" width="100%" max-width="600" />
                    </div>
                    <div class="panel-footer">Blockwise updating.</div>
                    </div>
                    
                    <div class="panel panel-info">
                        <a name="3"></a>
                        <div class="panel-heading">Figure 3</div>
                        <div class="panel-body">
                            <img src="img/trace_component.png" width="100%" max-width="600" />
                        </div>
                        <div class="panel-footer">Componentwise updating.</div>
                    </div>
                    
                    
                    
                    
                    <div class="panel panel-info">
                        <a name="4"></a>
                        <div class="panel-heading">Figure 4</div>
                        <div class="panel-body">
                            <img src="img/histogram.png" width="100%" max-width="600" />
                        </div>
                        <div class="panel-footer">Histogram of slice samples from the empirical distribution.</div>
                    </div>
                    
                    <p>When slice sampling, there are a number of parameter choices that are imporant. We want to choose our rectangle widths, burn-in, and thinning parameters appropriately. In testing, a thinning value of 10 reduced autocorrelation to less than 0.1 at a time lag of 1. We can see this result in figure <a href="#5">5</a>. We used the Gelman-Rubin potential scale reduction factor to determine if we were observing favorable mixing. Generally, a value less than 1.1 indicates good mixing. In both of our dimensions, the Gelman-Rubin statistic was less than this threshold. We also calculated the Geweke statistic, which is used to indicate convergence. A value less than 2 indicates convergence and for our draws, this statistic was $\ll$ 1. We can also examine convergence by looking at the trace plots for the samples. As we see in figure <a href="#6">6</a> these appear stationary.</p>
                    
                    
                    <div class="panel panel-info">
                        <a name="5"></a>
                        <div class="panel-heading">Figure 5</div>
                        <div class="panel-body">
                            <img src="img/autocorr-latlong.png" width="100%" max-width="600" />
                        </div>
                        <div class="panel-footer">Autocorrelation for the samples from latitude and longitude</div>
                    </div>
                    
                    
                    <div class="panel panel-info">
                        <a name="6"></a>
                        <div class="panel-heading">Figure 6</div>
                        <div class="panel-body">
                            <img src="img/trace-plots.png" width="100%" max-width="600" />
                        </div>
                        <div class="panel-footer">Trace plots for draws from the latitude and longitude</div>
                    </div>
                    
                    <h4>Events in time</h4>
                    
                    <p>As a modeling assumption, we separate the dimensions of space and time as being independent. To model events in time across the country, we use an autoregressive Poisson GLM. While standard autoregressive models create a linear relation between a future value and a previous value,
                    the Poisson GLM permits a linear relation between previous data and the mean of a Poisson distribution. This will allow us to retain the probabilistic interpretation of the events in time.</p>
                    
                    <p>In order to model events using a Poisson distribution, we must discretize our time dimension. We opted for month-long increments. The thinking behind this decision is that we want to use sample draws to run our aid optimizations. If a model like this were to be used in planning for future conflicts, having a month-long window for a plan seems like a good balance between precision and logistic concerns.</p>
                    
                    <p>The Autoregressive Poisson GLM model can be described as a log-linear relationship between the number of events of political violence and the mean of a Poisson distribution. We start with a timeseries,
                    $\mathbf{X} = \{x_0, x_1,\ldots, x_N\}$, of $N$ counts of events at each discretized point in time. We also start with a lag $\Lambda$ that is the number of previous time steps to include in the model. We can now describe our features at time $t$ as the $\Lambda$ previous time steps:
                    $\mathbf{X_{t, \Lambda}} = \{x_{t-\Lambda}, x_{t-\Lambda-1},\ldots, x_t\}$.</p>
                    
                    <p>The linear predictor in the autoregressive model at a time step is $\eta_t$, and it is related to the mean of the Poisson distribution,
                    $\mu_t$, by its canonical link function, $\log$.</p>
                    
                    $$\begin{aligned}
                    \eta_t &= \mathbf{X}_{t, \Lambda}'\beta. \\
                    \mu_t &= \log(\eta_t) = \log(\mathbf{X}_{t, \Lambda}'\beta) \\\end{aligned}$$
                    
                    <p>Finally, the only parameter to the Poisson distribution is this mean, so the distribution of counts, $k$, at some time t+1 can be given by:</p>
                    
                    $$\begin{aligned}
                    p(k | \mu_t) &= \frac{\mu_t^k}{k!}e^{-\mu_t} \\
                    p(k | \mathbf{X}_{t, \Lambda}, \beta) &= \frac{\log(\mathbf{X}_{t, \Lambda}'\beta)^k}{k!}e^{-\log(\mathbf{X}_{t, \Lambda}'\beta)} \end{aligned}$$
                    
                    <p>We can fit this model by using Fisher scoring to calculate $\beta_\mathrm{MLE}$, the coefficients of the model. Figure <a href="#7">7</a> shows this model as compared to actual rates of conflict incidence.</p>
                    
                    
                    <div class="panel panel-info">
                    <a name="7"></a>
                    <div class="panel-heading">Figure 7</div>
                    <div class="panel-body">
                    <img src="img/poisson-regression.png" width="100%" max-width="600" />
                    </div>
                    <div class="panel-footer">The Poisson regression model.</div>
                    </div>
                    
                    <h4>Putting together the spatial and temporal</h4>
                    
                    <p>We can now use our draws over space and time to generate a simulation of future conflicts in Uganda. These simulated scenarios will serve as the basis of our aid delivery optimization. The combination of modeling conflict events in space and time along with optimizing aid delivery could prove helpful to organizations such as the Red Cross in ordering supplies, allocating staff and volunteers, and developing infrastructure.
                    
                    </div>
                    </div>
                    
                    <div class="footer">
                    <p>S. Kim, G. Haslam, 2015</p>
                    </div>
                    
                    </div> <!-- /container -->
                    
                    
                    <!-- Bootstrap core JavaScript ================================================== -->
                    <!-- Placed at the end of the document so the pages load faster -->
                    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
                    <script src="https://code.jquery.com/jquery.js"></script>
                    <!-- Include all compiled plugins (below), or include individual files as needed -->
                    <script src="//netdna.bootstrapcdn.com/bootstrap/3.0.2/js/bootstrap.min.js"></script>
                    </body>
                    </html>